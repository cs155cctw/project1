{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_2008 = np.loadtxt('data/train_2008.csv', skiprows=1, delimiter=',')\n",
    "X_test_2008 = np.loadtxt('data/test_2008.csv', skiprows=1, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2008 = train_data_2008[:,:-1]\n",
    "Y_train_2008 = train_data_2008[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data_column(x):\n",
    "    '''\n",
    "    normalize the input data such that it is centered around zero and has standard deviation of 1.0\n",
    "    Inputs:\n",
    "        x: a (N, D) shaped numpy array containing the data points.\n",
    "    Outputs:\n",
    "        xp: a (N, D) shaped numpy array containing the normalized data points.\n",
    "    '''\n",
    "    xp = np.zeros_like(x)\n",
    "    \n",
    "    for idx_D in range(len(x[0,:])): #normalize each column independently\n",
    "        average = np.mean(x[:,idx_D])\n",
    "        std_dev = np.std(x[:,idx_D])\n",
    "        if std_dev > 0:\n",
    "            xp[:,idx_D] = (x[:, idx_D] - average)/std_dev\n",
    "        elif average != 0: #if all the elements are the same in that column, make all of them to be one\n",
    "            xp[:,idx_D] = x[:, idx_D]/average\n",
    "        else:\n",
    "            xp[:,idx_D] = x[:, idx_D]\n",
    "    \n",
    "    return xp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize each column of the data\n",
    "X_train_2008 = normalize_data_column(X_train_2008)\n",
    "X_test_2008 = normalize_data_column(X_test_2008)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the training data into training and validation dataset\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X_train_2008, Y_train_2008, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#estimator for adaboost\n",
    "ada_tree_estimator = DecisionTreeRegressor(max_features='sqrt', splitter='random', min_samples_split=4, max_depth=3)\n",
    "#adaboost regressor\n",
    "ab = AdaBoostRegressor(ada_tree_estimator, learning_rate=0.01, loss='square', n_estimators=1000)\n",
    "#fit\n",
    "ab.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_loss_curves(model, X_train, Y_train, X_test, Y_test):\n",
    "    plt.close('all')\n",
    "\n",
    "    Y_train_pred = np.zeros_like(Y_train)\n",
    "    Y_test_pred = np.zeros_like(Y_test)\n",
    "    losses_train = []\n",
    "    losses_test = []\n",
    "\n",
    "    # For each added classifier, store the new training and test losses.\n",
    "    for clf in model.estimators_:\n",
    "        Y_train_pred += clf.predict(X_train)\n",
    "        Y_test_pred += clf.predict(X_test)\n",
    "\n",
    "        losses_train.append(len(np.where(np.sign(Y_train_pred-0.5) != np.sign(Y_train-0.5))[0]) / len(Y_train_pred))\n",
    "        losses_test.append(len(np.where(np.sign(Y_test_pred-0.5) != np.sign(Y_test-0.5))[0]) / len(Y_test_pred))\n",
    "\n",
    "    # Plot the losses across n_clfs.\n",
    "    n_clfs = len(model.estimators_)\n",
    "    plt.plot(np.arange(1, n_clfs + 1), losses_train)\n",
    "    plt.plot(np.arange(1, n_clfs + 1), losses_test)\n",
    "    plt.title('Loss vs. n_clfs')\n",
    "    plt.legend(['Training loss', 'Test loss'])\n",
    "    plt.xlabel('n_clfs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_loss_curves(ab, X_train, Y_train, X_valid, Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## draw the ROC curve\n",
    "Y_valid_predict = ab.predict(X_valid)\n",
    "fpr, tpr, _ = roc_curve(Y_valid, Y_valid_predict)\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Background (false positives)')\n",
    "plt.ylabel('Signal (true positives)')\n",
    "plt.title(r'ROC curve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## calculate the AUC - area under the curve\n",
    "AUC = roc_auc_score(Y_valid, Y_valid_predict)\n",
    "print(AUC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make the prediction!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test_2008 = ab.predict(X_test_2008)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_2008 = np.arange(len(X_test_2008))\n",
    "target_2008 = np.copy(predict_test_2008)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm_2008 = np.stack([ids_2008,target_2008], axis=1)\n",
    "#let's name the submission file in this way\n",
    "#submission_2008or2012_date_version_algorithm_person.csv\n",
    "np.savetxt('submission/submission_2008_02092019_v1_Adaboost_Zhicai.csv', subm_2008, fmt='%d,%.6f', header='id,target', comments='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
