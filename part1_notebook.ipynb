{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_2008 = np.loadtxt('data/train_2008.csv', skiprows=1, delimiter=',')\n",
    "X_test_2008 = np.loadtxt('data/test_2008.csv', skiprows=1, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2008 = train_data_2008[:,:-1]\n",
    "Y_train_2008 = train_data_2008[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data_column(x):\n",
    "    '''\n",
    "    normalize the input data such that it is centered around zero and has standard deviation of 1.0\n",
    "    Inputs:\n",
    "        x: a (N, D) shaped numpy array containing the data points.\n",
    "    Outputs:\n",
    "        xp: a (N, D) shaped numpy array containing the normalized data points.\n",
    "    '''\n",
    "    xp = np.zeros_like(x)\n",
    "    \n",
    "    for idx_D in range(len(x[0,:])): #normalize each column independently\n",
    "        average = np.mean(x[:,idx_D])\n",
    "        std_dev = np.std(x[:,idx_D])\n",
    "        if std_dev > 0:\n",
    "            xp[:,idx_D] = (x[:, idx_D] - average)/std_dev\n",
    "        elif average != 0: #if all the elements are the same in that column, make all of them to be one\n",
    "            xp[:,idx_D] = x[:, idx_D]/average\n",
    "        else:\n",
    "            xp[:,idx_D] = x[:, idx_D]\n",
    "    \n",
    "    return xp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize each column of the data\n",
    "X_train_2008 = normalize_data_column(X_train_2008)\n",
    "X_test_2008 = normalize_data_column(X_test_2008)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the training data into training and validation dataset\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X_train_2008, Y_train_2008, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_parameter = \"adaboost_default_lr0p1_lossSquare_nest1000_minsamplesplit4_maxdepth5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#estimator for adaboost\n",
    "ada_tree_estimator = DecisionTreeRegressor(min_samples_split=4, max_depth=5)#, max_features='sqrt', splitter='random')\n",
    "#adaboost regressor\n",
    "ab = AdaBoostRegressor(ada_tree_estimator, learning_rate=0.1, loss='square', n_estimators=1000)\n",
    "#fit\n",
    "ab.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_loss_curves(model, X_train, Y_train, X_test, Y_test, cut):\n",
    "    plt.close('all')\n",
    "\n",
    "    Y_train_pred = np.zeros_like(Y_train)\n",
    "    Y_test_pred = np.zeros_like(Y_test)\n",
    "    losses_train = []\n",
    "    losses_test = []\n",
    "\n",
    "    # For each added classifier, store the new training and test losses.\n",
    "    for clf in model.estimators_:\n",
    "        Y_train_pred += clf.predict(X_train)\n",
    "        Y_test_pred += clf.predict(X_test)\n",
    "        #make the cut and take the sign\n",
    "        Y_train_pred_sign = np.where(Y_train_pred > cut, 1, 0)\n",
    "        Y_test_pred_sign = np.where(Y_test_pred > cut, 1, 0)\n",
    "        \n",
    "        losses_train.append(len(np.where(Y_train_pred_sign != Y_train)[0]) / len(Y_train_pred))\n",
    "        losses_test.append(len(np.where(Y_test_pred_sign != Y_test)[0]) / len(Y_test_pred))\n",
    "\n",
    "    # Plot the losses across n_clfs.\n",
    "    n_clfs = len(model.estimators_)\n",
    "    plt.plot(np.arange(1, n_clfs + 1), losses_train)\n",
    "    plt.plot(np.arange(1, n_clfs + 1), losses_test)\n",
    "    plt.title('Loss vs. n_clfs')\n",
    "    plt.legend(['Training loss', 'Test loss'])\n",
    "    plt.xlabel('n_clfs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_efficiency(Y_predict, cut, Y_test):\n",
    "    total = (Y_test).sum()\n",
    "    passing = ((Y_predict > cut) * Y_test).sum() # gives signal and passing cuts\n",
    "    return passing * 1.0 / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## find the best cut\n",
    "Y_train_predict = ab.predict(X_train)\n",
    "Y_valid_predict = ab.predict(X_valid)\n",
    "cuts1 = np.arange(0, 0.1, 0.00005)\n",
    "cuts2 = np.arange(0.1, 0.9, 0.001)\n",
    "cuts3 = np.arange(0.9, 1, 0.00005)\n",
    "cuts = np.concatenate([cuts1, cuts2, cuts3])\n",
    "# write cuts and efficiency to file\n",
    "with open('roc_cut_eff.txt', 'w') as textfile:\n",
    "    textfile.write(\"cut, efficiency_sig, efficiency_bkg \\n\")\n",
    "    for cut in cuts:\n",
    "        efficiency_sig = compute_efficiency(Y_valid_predict, cut, Y_valid) # compute efficiency at each cut point\n",
    "        efficiency_bkg = compute_efficiency(Y_valid_predict, cut, 1-Y_valid) # compute efficiency at each cut point\n",
    "        line = \"{},{},{}\\n\".format(cut, efficiency_sig, efficiency_bkg)\n",
    "        textfile.write(line) # save cut and efficiency to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize_loss_curves(ab, X_train, Y_train, X_valid, Y_valid, 0.405)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## calculate the AUC - area under the curve\n",
    "AUC_train = roc_auc_score(Y_train, Y_train_predict)\n",
    "print(AUC_train)\n",
    "AUC_valid = roc_auc_score(Y_valid, Y_valid_predict)\n",
    "print(AUC_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## draw the ROC curve\n",
    "fpr_train, tpr_train, _ = roc_curve(Y_train, Y_train_predict)\n",
    "fpr_valid, tpr_valid, _ = roc_curve(Y_valid, Y_valid_predict)\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr_train, tpr_train, color='blue',\n",
    "         lw=lw, label='training set, AUC = %.3f'%AUC_train)\n",
    "plt.plot(fpr_valid, tpr_valid, color='darkorange',\n",
    "         lw=lw, label='validation set, AUC = %.3f'%AUC_valid)\n",
    "plt.plot([0, 1], [0, 1], color='black', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Background (false positives)')\n",
    "plt.ylabel('Signal (true positives)')\n",
    "plt.legend(loc=0, shadow=True)\n",
    "plt.title(r'ROC curve')\n",
    "plt.savefig('plots/ROC_'+model_parameter+'.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make the prediction!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test_2008 = ab.predict(X_test_2008)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_2008 = np.arange(len(X_test_2008))\n",
    "target_2008 = np.copy(predict_test_2008)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm_2008 = np.stack([ids_2008,target_2008], axis=1)\n",
    "#let's name the submission file in this way\n",
    "#submission_2008or2012_date_version_algorithm_person.csv\n",
    "np.savetxt('submission/submission_2008_02102019_v2_'+model_parameter+'_Zhicai.csv', subm_2008, fmt='%d,%.6f', header='id,target', comments='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
